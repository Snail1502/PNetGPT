{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5Config, T5ForConditionalGeneration, T5Tokenizer, BertTokenizer\n",
    "from transformers import DataCollatorForSeq2Seq\n",
    "from transformers import Trainer, TrainingArguments, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_files = './data_ezsocket/merged_api_para_pcapdata_dataset20k.csv'\n",
    "# ; is the tab character in Python\n",
    "ezsocket_dataset = load_dataset(\"csv\", data_files=data_files, delimiter=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "####以下函数用于讲10进制数token化#####\n",
    "def format_decimal_as_hexadecimal(decimal_str):\n",
    "    # Convert the decimal string to an integer\n",
    "    decimal_number = int(decimal_str)\n",
    "    \n",
    "    # Convert the integer to a hexadecimal string\n",
    "    hex_str = hex(decimal_number)[2:]  # Strip the '0x' prefix\n",
    "    \n",
    "    # Ensure the length of the hex string is even\n",
    "    if len(hex_str) % 2 != 0:\n",
    "        hex_str = '0' + hex_str\n",
    "    \n",
    "    # Split the hex string into pairs of characters\n",
    "    hex_pairs = [hex_str[i:i+2] for i in range(0, len(hex_str), 2)]\n",
    "    \n",
    "    # Join the pairs with commas\n",
    "    formatted_hex = ','.join(hex_pairs)\n",
    "    \n",
    "    return formatted_hex\n",
    "\n",
    "\n",
    "def convert_number(num_str):\n",
    "    num = float(num_str)\n",
    "    if num.is_integer():\n",
    "        num = int(num)\n",
    "        sign = \"-\" if num < 0 else \"+\"\n",
    "        num_str = format_decimal_as_hexadecimal(str(num).lstrip('-'))\n",
    "        return f\"num,{sign},{num_str},num\"\n",
    "    else:\n",
    "        sign = \"-\" if num < 0 else \"+\"\n",
    "        num_str = num_str.lstrip('-')\n",
    "        integer_part, fractional_part = num_str.split('.')\n",
    "        combined_num = format_decimal_as_hexadecimal(integer_part + fractional_part.rstrip('0'))\n",
    "        pos_num = format_decimal_as_hexadecimal(len(fractional_part.rstrip('0')))\n",
    "        return f\"num,{sign},{combined_num},pos,{pos_num},num\"\n",
    "\n",
    "def process_segment(segment):\n",
    "    parts = segment.split(',')\n",
    "    for i, part in enumerate(parts):\n",
    "        if re.match(r'^-?\\d+(\\.\\d+)?$', part):  # Match integers and floating-point numbers\n",
    "            parts[i] = convert_number(part)\n",
    "    result = ','.join(parts)\n",
    "    result = result.replace(\",\", \" \")\n",
    "    return result\n",
    "####以上函数用于将10进制数token化：process_segment(segment)#####\n",
    "\n",
    "####以下函数用于将payload按两位分开，用','隔开#####\n",
    "def split_payload_into_pairs(text):\n",
    "    # 将文本按每两个字符分割\n",
    "    pairs = [text[i:i+2] for i in range(0, len(text), 2)]\n",
    "    # 用逗号连接分割后的文本\n",
    "    result = ' '.join(pairs)\n",
    "    return result\n",
    "####以上函数用于将payload按两位分开，用','隔开#####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afc47174753448ab84695ba5d54c9fe4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/20311 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de59cc32d391408eb85a99d6837faa2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/20311 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f2116eca446495d84caa2019c83e0f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/20311 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#使用map+lambda清洗数据\n",
    "# clear_ezsocket_dataset = ezsocket_dataset.map(lambda x: {\"Function and Parameters\": x[\"Function and Parameters\"].split(',', 1)[1]})\n",
    "clear_ezsocket_dataset = ezsocket_dataset.map(lambda x: {\"Function and Parameters\": [o.split(',', 1)[1] for o in x[\"Function and Parameters\"]]}, batched=True) #可加速处理，删除前面的时间戳\n",
    "clear_ezsocket_dataset = clear_ezsocket_dataset.map(lambda x: {\"Function and Parameters\": [process_segment(o) for o in x[\"Function and Parameters\"]]}, batched=True) #可加速处理，10进制参数token化\n",
    "clear_ezsocket_dataset = clear_ezsocket_dataset.map(lambda x: {\"Data Segment\": [split_payload_into_pairs(o) for o in x[\"Data Segment\"]]}, batched=True) #可加速处理，10进制参数token化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Function and Parameters', 'Data Segment'],\n",
       "        num_rows: 14623\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['Function and Parameters', 'Data Segment'],\n",
       "        num_rows: 1625\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['Function and Parameters', 'Data Segment'],\n",
       "        num_rows: 4063\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#划分训练集测试集和验证集\n",
    "ezsocket_dataset_tt = clear_ezsocket_dataset[\"train\"].train_test_split(train_size=0.8, seed=42)\n",
    "ezsocket_dataset_tvt = ezsocket_dataset_tt[\"train\"].train_test_split(train_size=0.9, seed=42)\n",
    "ezsocket_dataset_tvt[\"validation\"] = ezsocket_dataset_tvt.pop(\"test\")\n",
    "ezsocket_dataset_tvt[\"test\"] = ezsocket_dataset_tt[\"test\"]\n",
    "ezsocket_dataset_tvt\n",
    "#保存数据集使用：Arrow:\tDataset.save_to_disk()  CSV:\tDataset.to_csv()    JSON:\tDataset.to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer=BertTokenizer(vocab_file='./vocab.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a789515d83ee4e7487e1f216d8de7675",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=8):   0%|          | 0/14623 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lizedong/anaconda3/envs/py310_hug/lib/python3.10/site-packages/datasets/table.py:1421: FutureWarning: promote has been superseded by promote_options='default'.\n",
      "  table = cls._concat_blocks(blocks, axis=0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7896d46a8887468395ce4051759bf8d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=8):   0%|          | 0/1625 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ee43da8dc61401396635258fc488789",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=8):   0%|          | 0/4063 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tokenize_function(examples):\n",
    "    inputs = tokenizer(examples[\"Function and Parameters\"], padding=\"max_length\", truncation=True, max_length=50)\n",
    "    targets = tokenizer(examples[\"Data Segment\"], padding=\"max_length\", truncation=True, max_length=210)\n",
    "    \n",
    "    inputs[\"labels\"] = targets[\"input_ids\"]\n",
    "    return inputs\n",
    "\n",
    "\n",
    "tokenized_datasets = ezsocket_dataset_tvt.map(tokenize_function, batched=True, num_proc=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "358"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = T5Config(\n",
    "    vocab_size=358,\n",
    "    d_model=512,\n",
    "    d_kv=64,\n",
    "    d_ff=2048,\n",
    "    num_layers=6,\n",
    "    num_heads=8,\n",
    "    relative_attention_num_buckets=32,\n",
    "    dropout_rate=0.1,\n",
    "    layer_norm_epsilon=1e-6,\n",
    "    initializer_factor=1.0,\n",
    "    feed_forward_proj=\"relu\",\n",
    "    is_encoder_decoder=True,\n",
    "    use_cache=True,\n",
    "    pad_token_id=261,\n",
    "    eos_token_id=258,\n",
    "    decoder_start_token_id=261\n",
    ")\n",
    "\n",
    "model = T5ForConditionalGeneration(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44240384"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.num_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(\n",
    "    tokenizer,\n",
    "    model=model,\n",
    "    padding=\"longest\",\n",
    "    max_length=210\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./t5_pretrained\",\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    predict_with_generate=True,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    logging_steps=100,\n",
    "    save_steps=1000,\n",
    "    eval_steps=1000,\n",
    "    warmup_steps=1000,\n",
    "    max_steps=100000,\n",
    "    overwrite_output_dir=True,\n",
    "    save_total_limit=7,\n",
    "    fp16=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "261\n",
      "261\n"
     ]
    }
   ],
   "source": [
    "print(model.config.decoder_start_token_id)\n",
    "print(tokenizer.pad_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='100000' max='100000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [100000/100000 2:05:28, Epoch 54/55]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.171300</td>\n",
       "      <td>0.133441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.089300</td>\n",
       "      <td>0.063537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.057900</td>\n",
       "      <td>0.039577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.044200</td>\n",
       "      <td>0.035238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.037700</td>\n",
       "      <td>0.031315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.035700</td>\n",
       "      <td>0.030832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.033000</td>\n",
       "      <td>0.028762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.033400</td>\n",
       "      <td>0.028161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.030100</td>\n",
       "      <td>0.027273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.030700</td>\n",
       "      <td>0.027064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.028100</td>\n",
       "      <td>0.026792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.028300</td>\n",
       "      <td>0.026360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.028700</td>\n",
       "      <td>0.026491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.026800</td>\n",
       "      <td>0.025995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.026100</td>\n",
       "      <td>0.025310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.027000</td>\n",
       "      <td>0.025248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>0.025700</td>\n",
       "      <td>0.024852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.028200</td>\n",
       "      <td>0.024778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>0.026300</td>\n",
       "      <td>0.024215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.026000</td>\n",
       "      <td>0.024151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21000</td>\n",
       "      <td>0.025100</td>\n",
       "      <td>0.024484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>0.023700</td>\n",
       "      <td>0.024193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23000</td>\n",
       "      <td>0.024500</td>\n",
       "      <td>0.023765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24000</td>\n",
       "      <td>0.024000</td>\n",
       "      <td>0.023627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25000</td>\n",
       "      <td>0.024800</td>\n",
       "      <td>0.023445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26000</td>\n",
       "      <td>0.023800</td>\n",
       "      <td>0.023577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27000</td>\n",
       "      <td>0.022900</td>\n",
       "      <td>0.023292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28000</td>\n",
       "      <td>0.022900</td>\n",
       "      <td>0.023391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29000</td>\n",
       "      <td>0.023900</td>\n",
       "      <td>0.023016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>0.022600</td>\n",
       "      <td>0.023077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31000</td>\n",
       "      <td>0.022500</td>\n",
       "      <td>0.022846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32000</td>\n",
       "      <td>0.022100</td>\n",
       "      <td>0.023139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33000</td>\n",
       "      <td>0.021900</td>\n",
       "      <td>0.022908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34000</td>\n",
       "      <td>0.022700</td>\n",
       "      <td>0.022879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35000</td>\n",
       "      <td>0.022900</td>\n",
       "      <td>0.022789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36000</td>\n",
       "      <td>0.022000</td>\n",
       "      <td>0.022760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37000</td>\n",
       "      <td>0.021400</td>\n",
       "      <td>0.022542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38000</td>\n",
       "      <td>0.022000</td>\n",
       "      <td>0.022641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39000</td>\n",
       "      <td>0.020800</td>\n",
       "      <td>0.022508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40000</td>\n",
       "      <td>0.021200</td>\n",
       "      <td>0.022478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41000</td>\n",
       "      <td>0.020400</td>\n",
       "      <td>0.022513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42000</td>\n",
       "      <td>0.021100</td>\n",
       "      <td>0.022385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43000</td>\n",
       "      <td>0.020900</td>\n",
       "      <td>0.022622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44000</td>\n",
       "      <td>0.019600</td>\n",
       "      <td>0.022360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45000</td>\n",
       "      <td>0.020500</td>\n",
       "      <td>0.022440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46000</td>\n",
       "      <td>0.019700</td>\n",
       "      <td>0.022319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47000</td>\n",
       "      <td>0.019800</td>\n",
       "      <td>0.022657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48000</td>\n",
       "      <td>0.020100</td>\n",
       "      <td>0.022472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49000</td>\n",
       "      <td>0.019800</td>\n",
       "      <td>0.022198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.022347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51000</td>\n",
       "      <td>0.019200</td>\n",
       "      <td>0.022050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52000</td>\n",
       "      <td>0.019100</td>\n",
       "      <td>0.022224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53000</td>\n",
       "      <td>0.019200</td>\n",
       "      <td>0.022291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54000</td>\n",
       "      <td>0.019000</td>\n",
       "      <td>0.022211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55000</td>\n",
       "      <td>0.018500</td>\n",
       "      <td>0.022435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56000</td>\n",
       "      <td>0.018700</td>\n",
       "      <td>0.022269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57000</td>\n",
       "      <td>0.018600</td>\n",
       "      <td>0.022207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58000</td>\n",
       "      <td>0.018500</td>\n",
       "      <td>0.022408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59000</td>\n",
       "      <td>0.018800</td>\n",
       "      <td>0.022341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60000</td>\n",
       "      <td>0.018400</td>\n",
       "      <td>0.022111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61000</td>\n",
       "      <td>0.018100</td>\n",
       "      <td>0.022359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62000</td>\n",
       "      <td>0.018400</td>\n",
       "      <td>0.022197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63000</td>\n",
       "      <td>0.018700</td>\n",
       "      <td>0.022452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64000</td>\n",
       "      <td>0.017300</td>\n",
       "      <td>0.022506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65000</td>\n",
       "      <td>0.017700</td>\n",
       "      <td>0.022430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66000</td>\n",
       "      <td>0.017800</td>\n",
       "      <td>0.022417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67000</td>\n",
       "      <td>0.018200</td>\n",
       "      <td>0.022543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68000</td>\n",
       "      <td>0.017500</td>\n",
       "      <td>0.022619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69000</td>\n",
       "      <td>0.017500</td>\n",
       "      <td>0.022523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70000</td>\n",
       "      <td>0.017500</td>\n",
       "      <td>0.022790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71000</td>\n",
       "      <td>0.017600</td>\n",
       "      <td>0.022497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72000</td>\n",
       "      <td>0.017300</td>\n",
       "      <td>0.022674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73000</td>\n",
       "      <td>0.017400</td>\n",
       "      <td>0.022734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74000</td>\n",
       "      <td>0.016900</td>\n",
       "      <td>0.022821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75000</td>\n",
       "      <td>0.017600</td>\n",
       "      <td>0.022767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76000</td>\n",
       "      <td>0.016800</td>\n",
       "      <td>0.022912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77000</td>\n",
       "      <td>0.017100</td>\n",
       "      <td>0.022987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78000</td>\n",
       "      <td>0.016800</td>\n",
       "      <td>0.022842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79000</td>\n",
       "      <td>0.016600</td>\n",
       "      <td>0.023148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80000</td>\n",
       "      <td>0.017000</td>\n",
       "      <td>0.023092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81000</td>\n",
       "      <td>0.016600</td>\n",
       "      <td>0.023172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82000</td>\n",
       "      <td>0.016900</td>\n",
       "      <td>0.022995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>83000</td>\n",
       "      <td>0.016700</td>\n",
       "      <td>0.023238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84000</td>\n",
       "      <td>0.016300</td>\n",
       "      <td>0.023218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85000</td>\n",
       "      <td>0.016400</td>\n",
       "      <td>0.023688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86000</td>\n",
       "      <td>0.016600</td>\n",
       "      <td>0.023334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87000</td>\n",
       "      <td>0.016100</td>\n",
       "      <td>0.023331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88000</td>\n",
       "      <td>0.015900</td>\n",
       "      <td>0.023548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>89000</td>\n",
       "      <td>0.016500</td>\n",
       "      <td>0.023471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90000</td>\n",
       "      <td>0.016000</td>\n",
       "      <td>0.023551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>91000</td>\n",
       "      <td>0.016100</td>\n",
       "      <td>0.023452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92000</td>\n",
       "      <td>0.015800</td>\n",
       "      <td>0.023533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93000</td>\n",
       "      <td>0.016200</td>\n",
       "      <td>0.023599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94000</td>\n",
       "      <td>0.015600</td>\n",
       "      <td>0.023552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95000</td>\n",
       "      <td>0.016500</td>\n",
       "      <td>0.023536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96000</td>\n",
       "      <td>0.016200</td>\n",
       "      <td>0.023618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97000</td>\n",
       "      <td>0.015900</td>\n",
       "      <td>0.023569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98000</td>\n",
       "      <td>0.015600</td>\n",
       "      <td>0.023641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99000</td>\n",
       "      <td>0.015400</td>\n",
       "      <td>0.023655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100000</td>\n",
       "      <td>0.015900</td>\n",
       "      <td>0.023667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=100000, training_loss=0.026661254634857176, metrics={'train_runtime': 7529.7767, 'train_samples_per_second': 106.245, 'train_steps_per_second': 13.281, 'total_flos': 1.05728645234688e+16, 'train_loss': 0.026661254634857176, 'epoch': 54.7})"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310_hug",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
